{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joshi Soham P. --> For assignment 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joint probability (of co-occurrence) is most important in science\n",
    "#### and engineering in general, and in machine learning in particular.\n",
    "#### Refer to what was said about the GLCM (grey level co-occurrence matrix)\n",
    "#### of an image for example.\n",
    "#### The purpose of this assignment is to implement the computation\n",
    "#### of many information-theoretic measures associated with such joint probability,\n",
    "#### using TensorFlow functions.\n",
    "####   ...\n",
    "#### Refer to modules 4 and 5 again, if necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Recall that  log base 2 of x  =  (log base 2 of e) * (log base e of x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### So,    log base 2 of x =  1.44269 * log base e of x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  ....................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ............"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The usual import(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The usual Session object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define a TensorFlow placeholder to hold the joint probability J.\n",
    "#####    Sizes are not fixed in advance, so that the below functions\n",
    "#####    may be used on any such joint probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "J = tf.placeholder(\"float\", shape=[None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  The actual 3 joint probability tables must be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1q1 = [[0.125, 0.125], [0.5, 0.25]]\n",
    "p2q2 = [[0.08,0.01,0.10], [0.10,0.20,0.01], [0.06,0.08,0.20],[0.03,0.08,0.05]]\n",
    "p3q3 = [[0.,1.], [0.,0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define the joint entropy function for any joint probability table J,\n",
    "####     using appropriate TensorFlow functions.\n",
    "####     This entropy must be base 2.\n",
    "####     It should never produce NaN  ot Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def joint_entropy(J):\n",
    "    a = 0\n",
    "    for i in J:\n",
    "        shape = tf.shape(i)\n",
    "        fill = tf.fill(shape, 1e-10)\n",
    "        a = a -tf.reduce_sum(tf.multiply(i, tf.log(i+fill)*1.44269))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Show the joint entropy for p1q1, p2q2, p3q3 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint entropy of p1q1:  1.7499939\n",
      "Joint entropy of p2q2:  3.2119455\n",
      "Joint entropy of p3q3:  0.0\n"
     ]
    }
   ],
   "source": [
    "je_p1q1 = sess.run(joint_entropy(p1q1))\n",
    "je_p2q2 = sess.run(joint_entropy(p2q2))\n",
    "je_p3q3 = sess.run(joint_entropy(p3q3))\n",
    "\n",
    "print('Joint entropy of p1q1: ', je_p1q1)\n",
    "print('Joint entropy of p2q2: ', je_p2q2)\n",
    "print('Joint entropy of p3q3: ', je_p3q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define the function that extracts the probability vector\n",
    "####     of the first component in the probability table (marginalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def first(J):\n",
    "    vector = []\n",
    "    for i in J:\n",
    "        vector.append(sum(i))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Show the probability vector for the first component of p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First component of joint p1q1:  [0.25, 0.75]\n",
      "First component of joint p2q2:  [0.19, 0.31000000000000005, 0.34, 0.16]\n",
      "First component of joint p3q3:  [1.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print('First component of joint p1q1: ', (first(p1q1)))\n",
    "print('First component of joint p2q2: ', (first(p2q2)))\n",
    "print('First component of joint p3q3: ', (first(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Define the function that extracts the probability vector\n",
    "####     of the second component in the probability table (marginalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def second(J):\n",
    "    vector = []\n",
    "    length = len(J[0])\n",
    "    for i in range(length):\n",
    "        a = 0\n",
    "        for j in J:\n",
    "            a = a + j[i]\n",
    "        vector.append(a)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Show the probability vector for the second component of p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second component of joint p1q1:  [0.625, 0.375]\n",
      "Second component of joint p2q2:  [0.27, 0.37000000000000005, 0.36]\n",
      "Second component of joint p3q3:  [0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print('Second component of joint p1q1: ', (second(p1q1)))\n",
    "print('Second component of joint p2q2: ', (second(p2q2)))\n",
    "print('Second component of joint p3q3: ', (second(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Define the entropy function of the first component \n",
    "####     for any joint probability table J, using appropriate TensorFlow functions.\n",
    "####     This entropy must be base 2.\n",
    "####     It should never produce NaN  ot Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_first(J):\n",
    "    shape = tf.shape(J)\n",
    "    fill = tf.fill(shape, 1e-10)\n",
    "    return -tf.reduce_sum(tf.multiply(J, tf.log(J+fill)*1.44269))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Show the entropy for the first component of p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint entropy of p1q1:  0.81127536\n",
      "Joint entropy of p2q2:  1.9312049\n",
      "Joint entropy of p3q3:  -0.0\n"
     ]
    }
   ],
   "source": [
    "ef_p1q1 = sess.run(entropy_first(first(p1q1)))\n",
    "ef_p2q2 = sess.run(entropy_first(first(p2q2)))\n",
    "ef_p3q3 = sess.run(entropy_first(first(p3q3)))\n",
    "\n",
    "\n",
    "print('Joint entropy of p1q1: ', ef_p1q1)\n",
    "print('Joint entropy of p2q2: ', ef_p2q2)\n",
    "print('Joint entropy of p3q3: ', ef_p3q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Define the entropy function of the second component \n",
    "####     for any joint probability table J, using appropriate TensorFlow functions.\n",
    "####     This entropy must be base 2.\n",
    "####     It should never produce NaN  ot Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy_second(J):\n",
    "    shape = tf.shape(J)\n",
    "    fill = tf.fill(shape, 1e-10)\n",
    "    return -tf.reduce_sum(tf.multiply(J, tf.log(J+fill)*1.44269))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Show the entropy for the second component of p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint entropy of p1q1:  0.9544307\n",
      "Joint entropy of p2q2:  1.5713603\n",
      "Joint entropy of p3q3:  -0.0\n"
     ]
    }
   ],
   "source": [
    "es_p1q1 = sess.run(entropy_second(second(p1q1)))\n",
    "es_p2q2 = sess.run(entropy_second(second(p2q2)))\n",
    "es_p3q3 = sess.run(entropy_second(second(p3q3)))\n",
    "\n",
    "print('Joint entropy of p1q1: ', es_p1q1)\n",
    "print('Joint entropy of p2q2: ', es_p2q2)\n",
    "print('Joint entropy of p3q3: ', es_p3q3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. Define the conditional entropy function of the first component \n",
    "####       if (with respect to) second component, for any joint probability table J, \n",
    "####       using appropriate TensorFlow functions.\n",
    "####     Should be easy, if you recall your entropy formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_entropy_first_if_second(J):\n",
    "    return tf.reduce_mean(tf.subtract(joint_entropy(J), second(J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Show the conditional entropy H(first | second) for the joint p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional entropy of p1q1(first component| Second component) :  1.2499939\n",
      "Conditional entropy of p2q2(first component| Second component) :  2.8786123\n",
      "Conditional entropy of p3q3(first component| Second component) :  -0.5\n"
     ]
    }
   ],
   "source": [
    "print('Conditional entropy of p1q1(first component| Second component) : ', sess.run(conditional_entropy_first_if_second(p1q1)))\n",
    "print('Conditional entropy of p2q2(first component| Second component) : ', sess.run(conditional_entropy_first_if_second(p2q2)))\n",
    "print('Conditional entropy of p3q3(first component| Second component) : ', sess.run(conditional_entropy_first_if_second(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Define the conditional entropy function of the second component \n",
    "####       if (with respect to) first component, for any joint probability table J, \n",
    "####       using appropriate TensorFlow functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conditional_entropy_second_if_first(J):\n",
    "    return tf.reduce_mean(tf.subtract(joint_entropy(J), first(J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Show the conditional entropy H(second | first) for the joint p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional entropy of p1q1(Second component| first component) :  1.2499939\n",
      "Conditional entropy of p2q2(Second component| first component) :  2.9619455\n",
      "Conditional entropy of p3q3(Second component| first component) :  -0.5\n"
     ]
    }
   ],
   "source": [
    "print('Conditional entropy of p1q1(Second component| first component) : ', sess.run(conditional_entropy_second_if_first(p1q1)))\n",
    "print('Conditional entropy of p2q2(Second component| first component) : ', sess.run(conditional_entropy_second_if_first(p2q2)))\n",
    "print('Conditional entropy of p3q3(Second component| first component) : ', sess.run(conditional_entropy_second_if_first(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Define the mutual information function between the first component \n",
    "####       and the second component, for any joint probability table J, \n",
    "####       using appropriate TensorFlow functions.\n",
    "####     Should be easy, if you recall your entropy formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutual_information_first_and_second(J):\n",
    "    return tf.reduce_mean(tf.subtract(first(J), conditional_entropy_first_if_second(J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Show the mutual information I(first;second) for the joint p1q1, p2q2, p3q3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information of p1q1 (first;second) :  -0.7499939\n",
      "Mutual Information of p2q2 (first;second) :  -2.6286123\n",
      "Mutual Information of p3q3 (first;second) :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Mutual Information of p1q1 (first;second) : ', sess.run(mutual_information_first_and_second(p1q1)))\n",
    "print('Mutual Information of p2q2 (first;second) : ', sess.run(mutual_information_first_and_second(p2q2)))\n",
    "print('Mutual Information of p3q3 (first;second) : ', sess.run(mutual_information_first_and_second(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Define the mutual information function between the second component \n",
    "####       and the first component, for any joint probability table J, \n",
    "####       using appropriate TensorFlow functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mutual_information_second_and_first(J):\n",
    "    return tf.reduce_mean(tf.subtract(second(J), conditional_entropy_second_if_first(J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21. Show the mutual information I(second; first) for the joint p1q1, p2q2, p3q3.\n",
    "####    .......\n",
    "###  Since mutual information I(X;Y) is symmetric, the results must be identical to the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information of p1q1 (second;first) :  -0.7499939\n",
      "Mutual Information of p2q2 (second;first) :  -2.6286123\n",
      "Mutual Information of p3q3 (second;first) :  1.0\n"
     ]
    }
   ],
   "source": [
    "print('Mutual Information of p1q1 (second;first) : ', sess.run(mutual_information_second_and_first(p1q1)))\n",
    "print('Mutual Information of p2q2 (second;first) : ', sess.run(mutual_information_second_and_first(p2q2)))\n",
    "print('Mutual Information of p3q3 (second;first) : ', sess.run(mutual_information_second_and_first(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KL (and other divergences, distances) apply only to distributions\n",
    "### of the same length (on the same space of outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Define the Kullback-Leibler (relative entropy) function  between the first component \n",
    "####     and the second component for any joint probability table J, using appropriate TensorFlow functions.\n",
    "####     This entropy must be base 2.\n",
    "####     It should never produce NaN  ot Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kullback_leibler_first_and_second(J):\n",
    "    a = 0\n",
    "    length = len(J[0])\n",
    "    for i in range(length):\n",
    "        ele = []\n",
    "        shape = tf.shape(i)\n",
    "        fill = tf.fill(shape, 1e-10)\n",
    "        for j in J:\n",
    "            ele.append(j[i])\n",
    "        a = a + tf.reduce_sum(tf.multiply(ele[0], tf.log((fill + ele[0])/(fill+ele[1]))*1.44269))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Show the Kullback-Leibler divergence KL(first;second) for the joint p1q1 and p3q3.\n",
    "####       p2q2 cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullback-Leibler divergence for p1q1 KL(first;second) :  -0.3749987\n",
      "Kullback-Leibler divergence for p3q3 KL(first;second) :  33.219166\n"
     ]
    }
   ],
   "source": [
    "print('Kullback-Leibler divergence for p1q1 KL(first;second) : ', sess.run(kullback_leibler_first_and_second(p1q1)))\n",
    "print('Kullback-Leibler divergence for p3q3 KL(first;second) : ', sess.run(kullback_leibler_first_and_second(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Define the Kullback-Leibler (relative entropy) function  between the second component \n",
    "####     and the first component for any joint probability table J, using appropriate TensorFlow functions.\n",
    "####     This entropy must be base 2.\n",
    "####     It should never produce NaN  ot Inf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kullback_leibler_second_and_first(J):\n",
    "    a = 0\n",
    "    length = len(J[0])\n",
    "    for i in range(length):\n",
    "        ele = []\n",
    "        shape = tf.shape(i)\n",
    "        fill = tf.fill(shape, 1e-10)\n",
    "        for j in J:\n",
    "            ele.append(j[i])\n",
    "        a = a + tf.reduce_sum(tf.multiply(ele[1], tf.log((fill + ele[1])/(fill+ele[0]))*1.44269))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. Show the Kullback-Leibler divergence KL(second;first) for the joint p1q1 and p3q3.\n",
    "####       p2q2 cannot be used.\n",
    "####   ....\n",
    "###    KL(X;Y) is not symmetric, so you would not always get the same results as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullback-Leibler divergence for p1q1 KL(first;second) :  1.2499957\n",
      "Kullback-Leibler divergence for p3q3 KL(first;second) :  0.0\n"
     ]
    }
   ],
   "source": [
    "print('Kullback-Leibler divergence for p1q1 KL(first;second) : ', sess.run(kullback_leibler_second_and_first(p1q1)))\n",
    "print('Kullback-Leibler divergence for p3q3 KL(first;second) : ', sess.run(kullback_leibler_second_and_first(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   There is a true metric (true distance) defined for probability distributions of the same\n",
    "###    length, shown in my write-ups.\n",
    "### ...\n",
    "####   26. Define this true metric function between the components of any joint probability table J, \n",
    "####   using the conditional entropy functions you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_first_second(J):\n",
    "    return tf.reduce_sum(tf.add(conditional_entropy_second_if_first(J), conditional_entropy_first_if_second(J)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 27. Show the distance distance(first,second) for the joint p1q1 and p3q3.\n",
    "####       p2q2 cannot be used.\n",
    "####   ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True distance for p1q1:  2.4999878\n",
      "True distance for p3q3:  -1.0\n"
     ]
    }
   ],
   "source": [
    "print('True distance for p1q1: ', sess.run(distance_first_second(p1q1)))\n",
    "print('True distance for p3q3: ', sess.run(distance_first_second(p3q3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
